shuffle=False情况下，对比是否带target encoding的结果
不带:
Mean AUC: 0.9387870357004451
------------------------------
test1 auc:  0.9043504004698633
test2 auc: 0.9061880282854176

不带targetEncoding的时候,第一折比较低?
用后面的数据预测前面的数据是很难的,用前面的数据预测后面相对准一些

带:
Mean AUC: 0.9584667644816542
------------------------------
test1 auc:  0.8755618264804256
test2 auc: 0.8718226240558324
带targetEncoding的时候过拟合了.

检查是加了什么时间前后相关的特征(有可能是原始特征)


1.增加离test最近的100条样本
Total training time is 0:29:21.278784
AUCs: [0.9175316679447133, 0.9353898551379488, 0.9532476303946213, 0.9493429745075367]
Mean AUC: 0.938878031996205
------------------------------
test1 auc:  0.906284498310276
test2 auc: 0.9070504672768415
实验结果: 增加80条带label的数据后test1数据集上有略微提升,但是在test2上基本没有变化


[exp2]
kfold去掉第5折做bagging
使用全部五折:
Total training time is 1:00:37.222847
AUCs: [0.9169393985027141, 0.9351006605945301, 0.9528792888962798, 0.949460276704179, 0.9395555538045229]
Mean AUC: 0.9387870357004451
------------------------------
test1 auc:  0.9043504004698633
test2 auc: 0.9061880282854176

去掉第五折:
Total training time is 0:50:38.580905
AUCs: [0.9169393985027141, 0.9351006605945301, 0.9528792888962798, 0.949460276704179]
Mean AUC: 0.9385949061744256
------------------------------
test1 auc:  0.9057955073601175
test2 auc: 0.9070833835348824
实验结果分析: 去掉第五折的效果比使用全部五折的效果要好,test1提升14,test2提升9

去掉第四折和第五折:
Total training time is 0:30:22.710704
AUCs: [0.9169393985027141, 0.9354425536441534, 0.9528792888962798]
Mean AUC: 0.9350870803477157
------------------------------
test1 auc:  0.9061065020159863
test2 auc: 0.9064512580416358
实验结果分析: 同时去掉第4折和第5折的效果 不如 单独去掉第5折的效果, 说明第四折是有用的


去掉第五折带target encoding:
Total training time is 0:34:33.649586
AUCs: [0.9421305439042487, 0.9553311863836347, 0.9681212163851909, 0.9661813378822198]
Mean AUC: 0.9579410711388234
------------------------------
test1 auc:  0.8770263343798643
test2 auc: 0.8725817011133199
实验结果: target encoding有毒。。。

[exp3]
4->5获得5的迭代次数,34->5获得45的迭代次数,234->5获得345的迭代次数,1234->5获得2345的迭代次数,融合
Total training time is 0:24:55.764497
AUCs: [0.9284736312419287, 0.9335205239745952, 0.9366949392064268, 0.9395787711687055]
Mean AUC: 0.934566966397914
------------------------------
test1 auc:  0.9029893450563052
test2 auc: 0.903450588067056
实验结果: 效果不如kfold去掉第5折的结果好

八折融合的方式
Total training time is 0:57:30.851989
AUCs: [0.9284736312419287, 0.9335205239745952, 0.9366949392064268, 0.9395787711687055, None, 0.9351527711177244, 0.9530550580913791, 0.9498332388909452]
best_iters: [1406, 1252, 940, 1176, 1234, 3540, 1527, 1160]
Mean AUC: 0.9394727048131006
------------------------------
test1 auc:  0.9057645194042203
test2 auc: 0.9063941508112412
实验结果分析: 前五折迭代次数设置不合适


4.计算每步特征工程的耗时

5.线上提交: 把读取文件改掉,产生真实结果的代码删掉
local2, run: lgb2_kfold_submit.log


nohup python -u exp2.py 5000 > exp2.log 2>&1 &
nohup python -u lgb2_kfold_submit.py 5000 > lgb2_kfold_submit.log 2>&1 &

cpu机器1
ssh -i id_rsa caihengxing@35.233.158.158
cpu机器2
ssh -i id_rsa caihengxing@35.238.158.50

cd kaggle/kaggle-IEEE-CIS-Fraud-Detection/label/